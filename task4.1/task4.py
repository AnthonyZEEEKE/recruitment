# ä»»åŠ¡å››ï¼šCIFAR-10æ¨¡å‹ä¼˜åŒ–+è¿›é˜¶æŒ‡æ ‡åˆ†æï¼ˆé€‚é…ä»»åŠ¡ä¸‰ç¯å¢ƒï¼Œç›´æ¥è¿è¡Œï¼‰
import torch
import torch.nn as nn
import torch.optim as optim
from torchvision import datasets, transforms
from torch.utils.data import DataLoader, random_split
import matplotlib.pyplot as plt
import numpy as np
from tqdm import tqdm
import seaborn as sns
from sklearn.metrics import confusion_matrix, classification_report

# å›ºå®šéšæœºç§å­ï¼Œä¿è¯ç»“æœå¯å¤ç°ï¼ˆå’Œä»»åŠ¡ä¸‰ä¸€è‡´ï¼‰
seed = 42
torch.manual_seed(seed)
torch.cuda.manual_seed(seed)
np.random.seed(seed)
torch.backends.cudnn.deterministic = True

# è‡ªåŠ¨é€‚é…GPU/CPUï¼ˆå’Œä»»åŠ¡ä¸‰ä¸€è‡´ï¼Œæ— éœ€ä¿®æ”¹ï¼‰
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
print(f"è¿è¡Œè®¾å¤‡: {device}")

# ---------------------- 1. ä¼˜åŒ–ç‰ˆæ•°æ®å¢å¼ºï¼ˆæ ¸å¿ƒä¼˜åŒ–1ï¼šæå‡æ³›åŒ–èƒ½åŠ›ï¼‰ ----------------------
transform_train = transforms.Compose([
    transforms.RandomCrop(32, padding=4),
    transforms.RandomHorizontalFlip(),
    transforms.RandomRotation(15),  # æ–°å¢ï¼šéšæœºæ—‹è½¬15Â°ï¼Œå¢åŠ å›¾ç‰‡å¤šæ ·æ€§
    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2),  # æ–°å¢ï¼šé¢œè‰²æŠ–åŠ¨
    transforms.ToTensor(),
    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))
])

transform_test = transforms.Compose([
    transforms.ToTensor(),
    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))
])

# åŠ è½½æ•°æ®é›†ï¼ˆå¤ç”¨ä»»åŠ¡ä¸‰çš„dataï¼Œdownload=Falseé¿å…é‡å¤ä¸‹è½½ï¼‰
train_dataset_full = datasets.CIFAR10(root='./data', train=True, download=False, transform=transform_train)
test_dataset = datasets.CIFAR10(root='./data', train=False, download=False, transform=transform_test)

# åˆ’åˆ†è®­ç»ƒ/éªŒè¯é›†ï¼ˆå’Œä»»åŠ¡ä¸‰ä¸€è‡´ï¼š9:1ï¼‰
train_size = int(0.9 * len(train_dataset_full))
val_size = len(train_dataset_full) - train_size
train_dataset, val_dataset = random_split(train_dataset_full, [train_size, val_size])

# è‡ªé€‚åº”batch_sizeï¼ˆGPU=128ï¼ŒCPU=32ï¼Œè‡ªåŠ¨åŒ¹é…ï¼‰
batch_size = 128 if torch.cuda.is_available() else 32
train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=0)
val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=0)
test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=0)

# CIFAR-10ç±»åˆ«ï¼ˆå’Œä»»åŠ¡ä¸‰ä¸€è‡´ï¼‰
classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')

# ---------------------- 2. ä¼˜åŒ–ç‰ˆCNNæ¨¡å‹ï¼ˆæ ¸å¿ƒä¼˜åŒ–2ï¼šåŠ æ·±ç»“æ„+æ‰¹é‡å½’ä¸€åŒ–ï¼‰ ----------------------
class ImprovedCNN(nn.Module):
    def __init__(self, num_classes=10):
        super(ImprovedCNN, self).__init__()
        self.conv_layers = nn.Sequential(
            # å·ç§¯å±‚+æ‰¹é‡å½’ä¸€åŒ–ï¼ˆBatchNorm2dï¼‰ï¼šåŠ é€Ÿæ”¶æ•›ï¼Œç¨³å®šè®­ç»ƒ
            nn.Conv2d(3, 32, kernel_size=3, padding=1),
            nn.BatchNorm2d(32),  # æ–°å¢ï¼šæ‰¹é‡å½’ä¸€åŒ–ï¼Œè§£å†³æ¢¯åº¦æ¶ˆå¤±
            nn.ReLU(),
            nn.MaxPool2d(2, 2),
            
            nn.Conv2d(32, 64, kernel_size=3, padding=1),
            nn.BatchNorm2d(64),
            nn.ReLU(),
            nn.MaxPool2d(2, 2),
            
            nn.Conv2d(64, 128, kernel_size=3, padding=1),
            nn.BatchNorm2d(128),
            nn.ReLU(),
            nn.MaxPool2d(2, 2),
            
            nn.Conv2d(128, 256, kernel_size=3, padding=1),  # æ–°å¢ï¼šç¬¬å››å±‚å·ç§¯ï¼ŒåŠ æ·±ç‰¹å¾æå–
            nn.BatchNorm2d(256),
            nn.ReLU(),
            nn.MaxPool2d(2, 2),
        )
        # å…¨è¿æ¥å±‚ï¼šæé«˜Dropoutç‡ï¼Œè¿›ä¸€æ­¥ç¼“è§£è¿‡æ‹Ÿåˆ
        self.fc_layers = nn.Sequential(
            nn.Linear(256 * 2 * 2, 512),  # é€‚é…æ–°å·ç§¯å±‚çš„è¾“å‡ºç»´åº¦
            nn.ReLU(),
            nn.Dropout(0.6),  # ä»»åŠ¡ä¸‰æ˜¯0.5ï¼Œæ–°å¢ï¼šæé«˜åˆ°0.6ï¼Œå‡å°‘è¿‡æ‹Ÿåˆ
            nn.Linear(512, 128),
            nn.ReLU(),
            nn.Dropout(0.5),
            nn.Linear(128, num_classes)
        )
    
    def forward(self, x):
        x = self.conv_layers(x)
        x = x.view(x.size(0), -1)  # å±•å¹³ç‰¹å¾
        x = self.fc_layers(x)
        return x

# åˆå§‹åŒ–ä¼˜åŒ–æ¨¡å‹ï¼Œæ”¾åˆ°æŒ‡å®šè®¾å¤‡
model = ImprovedCNN().to(device)

# ---------------------- 3. ä¼˜åŒ–è®­ç»ƒç­–ç•¥ï¼ˆæ ¸å¿ƒä¼˜åŒ–3ï¼šå­¦ä¹ ç‡è¡°å‡+æ—©åœï¼‰ ----------------------
criterion = nn.CrossEntropyLoss()  # æŸå¤±å‡½æ•°å’Œä»»åŠ¡ä¸‰ä¸€è‡´
optimizer = optim.Adam(model.parameters(), lr=0.001)  # ä¼˜åŒ–å™¨å’Œä»»åŠ¡ä¸‰ä¸€è‡´
# æ–°å¢ï¼šå­¦ä¹ ç‡è¡°å‡â€”â€”æ¯20è½®å­¦ä¹ ç‡å‡åŠï¼Œå‰æœŸå¿«å­¦ï¼ŒåæœŸç²¾è°ƒ
scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=20, gamma=0.5)

num_epochs = 80  # ä¼˜åŒ–åæ”¶æ•›æ›´å¿«ï¼Œ80è½®è¶³å¤Ÿï¼ˆæ¯”ä»»åŠ¡ä¸‰100è½®çœæ—¶é—´ï¼‰
best_val_acc = 0.0  # æ—©åœä¸“ç”¨ï¼šä¿å­˜éªŒè¯é›†å‡†ç¡®ç‡æœ€é«˜çš„æ¨¡å‹
patience = 10  # æ–°å¢ï¼šæ—©åœâ€”â€”10è½®éªŒè¯é›†å‡†ç¡®ç‡æ²¡æå‡ï¼Œç›´æ¥åœæ­¢è®­ç»ƒï¼Œé¿å…è¿‡æ‹Ÿåˆ

# è®°å½•è®­ç»ƒæŒ‡æ ‡ï¼ˆæ–°å¢å­¦ä¹ ç‡è®°å½•ï¼‰
train_loss_list = []
val_loss_list = []
train_acc_list = []
val_acc_list = []
lr_list = []  # è®°å½•æ¯è½®å­¦ä¹ ç‡å˜åŒ–

# ---------------------- 4. å¼€å§‹è®­ç»ƒï¼ˆå¸¦æ—©åœï¼Œå…¨ç¨‹è‡ªåŠ¨ï¼‰ ----------------------
print("===== ä»»åŠ¡å››ï¼šä¼˜åŒ–æ¨¡å‹è®­ç»ƒå¼€å§‹ =====")
for epoch in range(num_epochs):
    # è®­ç»ƒé˜¶æ®µ
    model.train()
    train_loss = 0.0
    train_correct = 0
    train_total = 0
    
    train_bar = tqdm(train_loader, desc=f"ç¬¬{epoch+1}/{num_epochs}è½® è®­ç»ƒ")
    for images, labels in train_bar:
        images, labels = images.to(device), labels.to(device)
        
        outputs = model(images)
        loss = criterion(outputs, labels)
        
        optimizer.zero_grad()
        loss.backward()
        optimizer.step()
        
        train_loss += loss.item() * images.size(0)
        _, predict = torch.max(outputs, 1)
        train_total += labels.size(0)
        train_correct += (predict == labels).sum().item()
        
        train_bar.set_postfix(loss=loss.item(), å‡†ç¡®ç‡=100*train_correct/train_total)
    
    # è®¡ç®—è®­ç»ƒæŒ‡æ ‡
    train_loss_epoch = train_loss / train_total
    train_acc_epoch = 100 * train_correct / train_total
    
    # éªŒè¯é˜¶æ®µï¼ˆå’Œä»»åŠ¡ä¸‰ä¸€è‡´ï¼Œæ— æ¢¯åº¦è®¡ç®—ï¼‰
    model.eval()
    val_loss = 0.0
    val_correct = 0
    val_total = 0
    
    with torch.no_grad():
        val_bar = tqdm(val_loader, desc=f"ç¬¬{epoch+1}/{num_epochs}è½® éªŒè¯")
        for images, labels in val_bar:
            images, labels = images.to(device), labels.to(device)
            outputs = model(images)
            loss = criterion(outputs, labels)
            
            val_loss += loss.item() * images.size(0)
            _, predict = torch.max(outputs, 1)
            val_total += labels.size(0)
            val_correct += (predict == labels).sum().item()
            
            val_bar.set_postfix(loss=loss.item(), å‡†ç¡®ç‡=100*val_correct/val_total)
    
    val_loss_epoch = val_loss / val_total
    val_acc_epoch = 100 * val_correct / val_total
    
    # å­¦ä¹ ç‡è¡°å‡ç”Ÿæ•ˆ
    scheduler.step()
    lr_list.append(optimizer.param_groups[0]['lr'])
    
    # ä¿å­˜æŒ‡æ ‡
    train_loss_list.append(train_loss_epoch)
    val_loss_list.append(val_loss_epoch)
    train_acc_list.append(train_acc_epoch)
    val_acc_list.append(val_acc_epoch)
    
    # æ—©åœé€»è¾‘ï¼šä¿å­˜æœ€ä¼˜æ¨¡å‹ï¼Œé¿å…è¿‡æ‹Ÿåˆ
    if val_acc_epoch > best_val_acc:
        best_val_acc = val_acc_epoch
        patience_counter = 0
        torch.save(model.state_dict(), "task4_best_model.pth")  # ä¿å­˜æœ€ä¼˜æ¨¡å‹æƒé‡
    else:
        patience_counter += 1
        if patience_counter >= patience:
            print(f"æ—©åœè§¦å‘ï¼ç¬¬{epoch+1}è½®éªŒè¯é›†å‡†ç¡®ç‡æœªæå‡ï¼Œåœæ­¢è®­ç»ƒ")
            break  # ç›´æ¥ç»ˆæ­¢è®­ç»ƒï¼ŒèŠ‚çœæ—¶é—´
    
    print(f"ç¬¬{epoch+1}è½®å®Œæˆ | è®­ç»ƒå‡†ç¡®ç‡:{train_acc_epoch:.2f}% | éªŒè¯å‡†ç¡®ç‡:{val_acc_epoch:.2f}% | å½“å‰å­¦ä¹ ç‡:{lr_list[-1]:.6f}\n")

# ---------------------- 5. æµ‹è¯•é›†è¿›é˜¶è¯„ä¼°ï¼ˆä»»åŠ¡å››æ ¸å¿ƒï¼šå¤šæŒ‡æ ‡åˆ†æï¼‰ ----------------------
print("===== åŠ è½½æœ€ä¼˜æ¨¡å‹ï¼Œå¼€å§‹æµ‹è¯•é›†è¿›é˜¶åˆ†æ =====")
model.load_state_dict(torch.load("task4_best_model.pth", map_location=device))
model.eval()

# æ”¶é›†æµ‹è¯•é›†æ‰€æœ‰ç»“æœï¼ˆç”¨äºæ··æ·†çŸ©é˜µ/ç±»åˆ«åˆ†æï¼‰
test_correct = 0
test_total = 0
all_preds = []
all_labels = []

with torch.no_grad():
    for images, labels in test_loader:
        images, labels = images.to(device), labels.to(device)
        outputs = model(images)
        _, predict = torch.max(outputs, 1)
        
        test_total += labels.size(0)
        test_correct += (predict == labels).sum().item()
        
        all_preds.extend(predict.cpu().numpy())
        all_labels.extend(labels.cpu().numpy())

# æœ€ç»ˆæµ‹è¯•é›†å‡†ç¡®ç‡
test_acc = 100 * test_correct / test_total
print(f"===== ä»»åŠ¡å››æœ€ç»ˆæµ‹è¯•é›†å‡†ç¡®ç‡: {test_acc:.2f}% =====")

# è®¡ç®—æ¯ä¸ªç±»åˆ«çš„å•ç‹¬å‡†ç¡®ç‡ï¼ˆä»»åŠ¡å››å¿…åˆ†ææŒ‡æ ‡ï¼‰
class_correct = list(0. for _ in range(10))
class_total = list(0. for _ in range(10))
with torch.no_grad():
    for images, labels in test_loader:
        images, labels = images.to(device), labels.to(device)
        outputs = model(images)
        _, predicted = torch.max(outputs, 1)
        c = (predicted == labels).squeeze()
        for i in range(len(labels)):
            label = labels[i]
            class_correct[label] += c[i].item()
            class_total[label] += 1

# æ‰“å°æ¯ä¸ªç±»åˆ«å‡†ç¡®ç‡
class_acc = []
print("\n===== æ¯ä¸ªç±»åˆ«çš„åˆ†ç±»å‡†ç¡®ç‡ =====")
for i in range(10):
    acc = 100 * class_correct[i] / class_total[i]
    class_acc.append(acc)
    print(f"{classes[i]}: {acc:.2f}%")

# ---------------------- 6. è‡ªåŠ¨ç”Ÿæˆä»»åŠ¡å››æ‰€æœ‰å¯è§†åŒ–/æ–‡æœ¬æ–‡ä»¶ï¼ˆå¿…äº¤ï¼‰ ----------------------
# åå½’ä¸€åŒ–å‡½æ•°ï¼ˆå’Œä»»åŠ¡ä¸‰ä¸€è‡´ï¼Œä¿è¯å›¾ç‰‡æ­£å¸¸æ˜¾ç¤ºï¼‰
def denormalize(img):
    mean = torch.tensor([0.4914, 0.4822, 0.4465]).view(3,1,1)
    std = torch.tensor([0.2023, 0.1994, 0.2010]).view(3,1,1)
    img = img * std + mean
    return img.clamp(0,1)

# å›¾1ï¼šè®­ç»ƒæ›²çº¿+å­¦ä¹ ç‡å˜åŒ–ï¼ˆä¼˜åŒ–ç‰ˆï¼Œ3ä¸ªå­å›¾ï¼‰
plt.figure(figsize=(15, 5))
# å­å›¾1ï¼šLossæ›²çº¿
plt.subplot(1,3,1)
plt.plot(train_loss_list, label="è®­ç»ƒLoss", color="#1f77b4")
plt.plot(val_loss_list, label="éªŒè¯Loss", color="#ff7f0e")
plt.xlabel("è®­ç»ƒè½®æ¬¡")
plt.ylabel("Losså€¼")
plt.title("Losså˜åŒ–æ›²çº¿ï¼ˆä¼˜åŒ–ç‰ˆï¼‰")
plt.legend()
plt.grid(alpha=0.3)
# å­å›¾2ï¼šå‡†ç¡®ç‡æ›²çº¿
plt.subplot(1,3,2)
plt.plot(train_acc_list, label="è®­ç»ƒå‡†ç¡®ç‡", color="#1f77b4")
plt.plot(val_acc_list, label="éªŒè¯å‡†ç¡®ç‡", color="#ff7f0e")
plt.xlabel("è®­ç»ƒè½®æ¬¡")
plt.ylabel("å‡†ç¡®ç‡(%)")
plt.title("å‡†ç¡®ç‡å˜åŒ–æ›²çº¿ï¼ˆä¼˜åŒ–ç‰ˆï¼‰")
plt.legend()
plt.grid(alpha=0.3)
# å­å›¾3ï¼šå­¦ä¹ ç‡è¡°å‡æ›²çº¿
plt.subplot(1,3,3)
plt.plot(lr_list, color="#2ca02c")
plt.xlabel("è®­ç»ƒè½®æ¬¡")
plt.ylabel("å­¦ä¹ ç‡")
plt.title("å­¦ä¹ ç‡è¡°å‡æ›²çº¿")
plt.grid(alpha=0.3)
plt.tight_layout()
plt.savefig("task4_è®­ç»ƒæ›²çº¿_ä¼˜åŒ–ç‰ˆ.png", dpi=300)
plt.close()
print("âœ… å·²ç”Ÿæˆï¼štask4_è®­ç»ƒæ›²çº¿_ä¼˜åŒ–ç‰ˆ.png")

# å›¾2ï¼šæ··æ·†çŸ©é˜µï¼ˆä»»åŠ¡å››æ ¸å¿ƒè¿›é˜¶æŒ‡æ ‡ï¼Œå±•ç¤ºç±»åˆ«é—´è¯¯åˆ†æƒ…å†µï¼‰
cm = confusion_matrix(all_labels, all_preds)
plt.figure(figsize=(10, 8))
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=classes, yticklabels=classes)
plt.xlabel('é¢„æµ‹ç±»åˆ«', fontsize=12)
plt.ylabel('çœŸå®ç±»åˆ«', fontsize=12)
plt.title('CIFAR-10æ··æ·†çŸ©é˜µï¼ˆä¼˜åŒ–ç‰ˆæ¨¡å‹ï¼‰', fontsize=14)
plt.tight_layout()
plt.savefig("task4_æ··æ·†çŸ©é˜µ.png", dpi=300)
plt.close()
print("âœ… å·²ç”Ÿæˆï¼štask4_æ··æ·†çŸ©é˜µ.png")

# å›¾3ï¼šç±»åˆ«å‡†ç¡®ç‡æŸ±çŠ¶å›¾ï¼ˆç›´è§‚å±•ç¤ºå„å“ç±»è¡¨ç°ï¼‰
plt.figure(figsize=(12, 6))
bars = plt.bar(classes, class_acc, color='skyblue', edgecolor='black')
plt.xlabel('ç±»åˆ«', fontsize=12)
plt.ylabel('å‡†ç¡®ç‡(%)', fontsize=12)
plt.title('æ¯ä¸ªç±»åˆ«çš„åˆ†ç±»å‡†ç¡®ç‡ï¼ˆä¼˜åŒ–ç‰ˆæ¨¡å‹ï¼‰', fontsize=14)
plt.ylim(0, 100)
# æŸ±å­ä¸Šæ ‡æ³¨å…·ä½“æ•°å€¼
for bar, acc in zip(bars, class_acc):
    plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 1, f"{acc:.1f}%", ha='center')
plt.tight_layout()
plt.savefig("task4_ç±»åˆ«å‡†ç¡®ç‡.png", dpi=300)
plt.close()
print("âœ… å·²ç”Ÿæˆï¼štask4_ç±»åˆ«å‡†ç¡®ç‡.png")

# å›¾4ï¼šé”™è¯¯åˆ†ç±»æ¡ˆä¾‹ï¼ˆå¸¦çœŸå®/é¢„æµ‹æ ‡ç­¾ï¼Œåˆ†ææ¨¡å‹çŸ­æ¿ï¼‰
plt.figure(figsize=(12, 6))
wrong_idx = np.where(np.array(all_preds) != np.array(all_labels))[0]
plt.suptitle("ä¼˜åŒ–æ¨¡å‹é”™è¯¯åˆ†ç±»æ¡ˆä¾‹ï¼ˆçœŸå®æ ‡ç­¾/é¢„æµ‹æ ‡ç­¾ï¼‰", fontsize=14)
for i in range(6):
    idx = wrong_idx[i]
    img, _ = test_dataset[idx]
    img = denormalize(img)
    true_label = classes[all_labels[idx]]
    pred_label = classes[all_preds[idx]]
    plt.subplot(2, 3, i+1)
    plt.imshow(img.permute(1,2,0))
    plt.title(f"çœŸå®ï¼š{true_label}\né¢„æµ‹ï¼š{pred_label}", fontsize=10)
    plt.axis("off")
plt.tight_layout()
plt.savefig("task4_é”™è¯¯åˆ†ç±»æ¡ˆä¾‹.png", dpi=300)
plt.close()
print("âœ… å·²ç”Ÿæˆï¼štask4_é”™è¯¯åˆ†ç±»æ¡ˆä¾‹.png")

# ç”Ÿæˆåˆ†ç±»æŠ¥å‘Šï¼ˆæ–‡æœ¬æ–‡ä»¶ï¼Œå«ç²¾å‡†ç‡/å¬å›ç‡/F1å€¼ï¼Œä»»åŠ¡å››å¿…äº¤ï¼‰
with open("task4_åˆ†ç±»æŠ¥å‘Š.txt", "w", encoding="utf-8") as f:
    f.write("===== CIFAR-10åˆ†ç±»æŠ¥å‘Šï¼ˆä¼˜åŒ–ç‰ˆæ¨¡å‹ï¼‰=====\n")
    f.write(classification_report(all_labels, all_preds, target_names=classes, digits=2))
print("âœ… å·²ç”Ÿæˆï¼štask4_åˆ†ç±»æŠ¥å‘Š.txt")

# ä¿å­˜æœ€ç»ˆæ¨¡å‹æƒé‡
torch.save(model.state_dict(), "task4_final_model.pth")
print("âœ… å·²ä¿å­˜ï¼štask4_final_model.pthï¼ˆæœ€ç»ˆæ¨¡å‹æƒé‡ï¼‰")

print("\n===== ä»»åŠ¡å››æ‰€æœ‰æ–‡ä»¶ç”Ÿæˆå®Œæˆï¼=====")
print("ğŸ“ ç”Ÿæˆæ–‡ä»¶å‡åœ¨UD_task3æ–‡ä»¶å¤¹å†…ï¼Œç›´æ¥ç”¨äºæäº¤ï¼")