一，任务描述：完成 CIFAR-10 数据集的分类任务。
我的思路：基于简单的 CNN 实现 CIFAR-10 分类，测试集准确率≥50%（实际达成≥70%），完成训练可视化、Debug 复盘、模型结果分析。

二，任务执行
阶段1.选择模型，选择CNN，因为这个在ai的帮助下我能大致看懂，要求准确率达到50%以上，不过实际上达到了78.92%
阶段2：环境检查与依赖补全
打开 Anaconda Prompt，激活指定虚拟环境，执行python --version/torch.__version__验证环境是否符合要求，确认 Python≥3.8、PyTorch 已安装；
执行pip install matplotlib numpy tqdm -i 清华源安装任务三必备依赖，解决第三方库缺失问题；
在桌面创建UD_task3文件夹，新建task3.py文件。
阶段3：代码首次运行与数据集下载
执行cd Desktop/UD_task3切换工作目录，执行python task3.py启动代码；
代码自动下载 CIFAR-10 数据集至data文件夹，下载完成后自动进入训练阶段（下载时必须用vpn，中途还断网一次）；
确认代码无即时报错，进度条正常滚动，判定运行环境无问题。
阶段4：模型训练过程
训练轮次：100 轮，全程自动运行，无需手动干预；
训练观察：前 10 轮训练 / 验证准确率快速上升，Loss 快速下降；30 轮后准确率增长放缓，Loss 趋于稳定；60 轮后基本收敛，无大幅震荡；
训练完成：代码自动打印最终测试集准确率，生成 3 张可视化图片和 1 个模型权重文件。
阶段5：GitHub 上传
文件筛选：确定需上传 GitHub 的核心文件（代码 + 3 张可视化图），排除大体积的data数据集文件夹。

三，核心结果记录
1. 模型训练核心指标
项目	实际结果
模型结构	SimpleCNN（3 层卷积 + 2 层全连接轻量化 CNN）
训练轮次	100 轮
最终训练集准确率	<77.46%>
最终验证集准确率	<77.98%>
最终测试集准确率	<78.92%>
收敛轮次	<约50轮>
Loss 曲线变化	整体呈下降趋势，前期快速下降，后期趋于平稳，无明显震荡 / 上升
2. 可视化结果说明
task3_训练曲线.png：清晰展示训练 / 验证的 Loss 和准确率变化趋势，可直观看到模型收敛过程，无过拟合 / 欠拟合特征；
task3_正确分类示例.png：5 张分类正确的图片，覆盖cat，ship,frog等类别，真实标签与预测标签完全一致；
task3_错误分类示例.png：5 张分类错误的图片，主要集中于car truck,frog bird等外形相似的类别，为后续模型优化提供方向。

四、问题与 Debug 复盘
数据集下载慢/下载失败，进度条卡住>	1. 判定为网络问题，官方源访问速度慢；2. 排除代码问题（代码中 download=True 为默认正确设置）
1. 等待网络恢复后重新运行；2. 备选方案：手动下载数据集放到 data 文件夹，修改 download=False

代码讲解
任务三代码分为 8 个核心部分：
1.导入工具库 相当于 “搬工具箱”(第 1-8 行,这几行是 “搬工具”，把训练模型需要的所有 “零件” 都导入进来，比如搭模型用的torch.nn、画图用的matplotlib、显示进度的tqdm)

2.固定随机种子 保证结果可复现(第 10-14 行,模型训练里有很多 “随机操作”（比如初始化参数、打乱数据），固定种子后，你每次运行代码得到的准确率、Loss 都一样，不会这次 70%、下次 65%，方便复现结果。)

3.自动适配 GPU/CPU 让代码兼容不同设备(代码会自动检查你的电脑有没有显卡（CUDA），有就用 GPU 跑（快 10 倍以上），没有就用 CPU 跑（慢但能运行）；print会告诉你最终用的是啥设备，方便核对。)

4.数据加载 + 预处理 准备训练用的 CIFAR-10 图片(第 19-47 行)
  4.1图片预处理（代码第 19-28 行）
      (图片原始格式是 “像素矩阵”，不能直接喂给模型，需要 “加工”：
      训练集加随机裁剪 / 翻转：相当于 “多造一些不同角度的图片”，让模型学的更全面，缓解过拟合；
      测试集不加随机操作：因为测试要测模型的真实水平，不能改图片；
      归一化：把像素值从 0-255 改成均值 0、方差 1 的分布，模型学起来更快。)
  4.2加载 CIFAR-10 数据集（代码第 30-33 行）
      root='./data'：数据集下载到UD_task3/data文件夹里；
      train=True：加载训练集（5 万张图片），train=False：加载测试集（1 万张图片）；
      download=True：第一次运行自动下载，后续运行会跳过下载；
      transform：把上面的预处理规则应用到图片上。
  4.3拆分训练集 / 验证集（代码第 35-37 行）
      把 5 万张训练集拆成 “4.5 万张训练 + 5000 张验证”：
      训练集：让模型学知识；
      验证集：每轮训练完，用验证集测模型效果，避免模型 “死记硬背” 训练集（过拟合）。
  4.4 数据加载器（代码第 39-42 行）
      数据加载器是 “送餐员”，把图片分批喂给模型：
      shuffle=True：训练集每次打乱顺序，避免模型学 “顺序规律”（比如一直先看猫、再看狗）；
      shuffle=False：验证 / 测试集不用打乱，不影响结果；
      num_workers=0：单线程加载，新手不用改，改大了容易报错。
  4.5 定义类别名称（代码第 44-45 行）
      CIFAR-10 的 10 类图片对应的名字，后续可视化时，能把 “数字 0” 变成 “plane”，方便看结果。

5.搭建 SimpleCNN 模型 定义神经网络结构(代码第 47-74 行）
这是模型的 “骨架”，分成两部分：
卷积层：像 “放大镜” 一样，一层一层找图片的特征（比如先找边缘，再找形状，最后找 “猫耳朵”“汽车轮子”）；
全连接层：把卷积找到的特征汇总，判断 “这张图是猫还是狗”；
forward函数：定义图片 “走的路径”，输入一张图，先过卷积、再展平、再过全连接，最后输出 10 个预测值（每个类别一个分数）。

6.训练配置 设定 “学习规则”（代码第 76-84 行）
损失函数（criterion）：模型预测错了，它会告诉模型 “错得多离谱”（比如把猫认成狗，Loss 值就高）；
优化器（optimizer）：根据 Loss 值，调整模型参数，让模型下次少犯错（lr=0.001 是 “步长”，步长太大容易学错，太小学的慢）；
num_epochs=100：模型把训练集看 100 遍，看的越多，学的越扎实（但太多会过拟合）；
4 个列表：记录每轮的 Loss 和准确率，后续用来画图。

7.开始训练 模型学习的核心过程（代码第 86-150 行）
  7.1训练阶段（代码第 88-118 行）
     每一轮训练的流程：
     拿 64 张图片喂给模型 → 模型输出 10 个预测分数；
     算 Loss（错得多离谱） → 优化器根据 Loss 调整模型参数；
     统计这 64 张图对了多少 → 累加到总数里；
     一轮结束后，算这轮的平均 Loss 和准确率，存到列表里。
  7.2 验证阶段（代码第 120-140 行）
      验证阶段和训练阶段几乎一样，但有两个关键区别：
      model.eval()：模型进入 “评估模式”，不更新参数（只是考试，不是学习）；
      with torch.no_grad()：关闭梯度计算，跑的更快，也避免误改参数。
  7.3 保存指标 + 打印结果（代码第 142-148 行）
      把每轮的训练 / 验证 Loss、准确率存到列表里（后续画图用），然后打印出来，方便你看模型有没有在进步。

8.测试集评估 + 可视化 验证效果 + 生成必交图片（代码第 152-230 行）
  8.1 测试集评估（代码第 152-178 行）
  训练完模型后，用 “从没见过的” 1 万张测试集图片最终考核模型，统计准确率；同时保存图片、预测标签、真实标签，后续用来画 “正确 / 错误分类示例”。
  8.2 可视化（代码第 180-230 行）
  denormalize函数：把归一化的图片 “还原”，否则画出来的图片是偏黑 / 偏白的，看不清；
  画 Loss / 准确率曲线：直观展示模型 “学习过程”，Loss 下降、准确率上升说明模型在进步；
  画正确 / 错误示例：展示模型的实际分类效果，是任务三必交的可视化内容；
  torch.save：保存训练好的模型，后续任务四可以直接加载，不用重新训练。

任务三代码的核心逻辑可以浓缩为 3 句话：
准备数据：下载 CIFAR-10，预处理后分成训练 / 验证 / 测试集，分批喂给模型；
训练模型：让 SimpleCNN 看 100 轮训练集，每轮学完用验证集考试，调整参数减少错误；
验证效果：用测试集最终考核模型，生成 Loss 曲线、分类示例等可视化结果。




