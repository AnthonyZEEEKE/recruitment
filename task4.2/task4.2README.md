一，创新点：对比任务三的核心改动
  1. 策略优化
   （1）Warmup 学习率预热：前 5 轮线性提升学习率，解决训练初期梯度不稳定问题，避免模型震荡发散。
      (深度学习训练中的一种学习率调整策略，核心逻辑是「先慢后快」，帮模型平稳起步：
      1. 先理解两个关键词
       学习率：控制模型参数更新的「步长」。步长太大容易「走歪」（震荡），太小又「走得慢」（收敛慢）。
       训练初期：模型刚接触数据，对规律还很陌生，梯度（参数更新的方向）往往不稳定。
      2. Warmup 做了什么？
       前 5 轮（或前几步）不直接用设定好的大学习率，而是从一个很小的学习率开始，线性地逐步增加到目标学习率。比如：目标学习率是 0.01，那第 1 轮用 0.002，第 2 轮 0.004…… 第 5 轮升到 0.01，之后再用 0.01 正常训        练。
      3. 为什么要这么做？
       训练初期模型「心里没底」，如果一开始步长太大，容易在参数空间里「乱撞」（震荡），甚至直接「走偏」（发散，训练失败）。Warmup 相当于让模型先「小步试探」，慢慢找到感觉，等梯度稳定了再「大步前进」，能让训练更        平稳。)
      （举个生活化的例子：就像开车起步，先轻踩油门慢慢提速，等车稳了再正常加速，不容易熄火或失控～）

   （2）Mixup 数据混合增强：对训练样本做线性插值，扩充数据分布，强制模型学习样本间的线性关系，缓解过拟合。
      1. Mixup 不会直接用原图 / 原数据训练，而是随机挑两个训练样本，按比例 “揉” 在一起，生成一个新样本。
       举个直观的例子（以图像分类为例）：
       样本 A：一张猫的图片，标签是「猫」（可以理解为 “猫的概率 = 1，狗的概率 = 0”）；
       样本 B：一张狗的图片，标签是「狗」（“狗的概率 = 1，猫的概率 = 0”）；
       Mixup 操作：随机选一个比例（比如 0.7），把 A 的像素值 ×0.7 + B 的像素值 ×0.3，生成一张 “70% 像猫 + 30% 像狗” 的新图；同时标签也按同样比例混合：「猫的概率 = 0.7，狗的概率 = 0.3」。
       这里的 “线性插值”，本质就是按权重加权混合（权重加起来等于 1）。
      2. 为什么要这么做？解决两个痛点
        痛点 1：数据不够 “丰富”真实训练数据往往有限，且分布比较 “窄”（比如只有 “纯猫”“纯狗”）。Mixup 通过混合样本，强行扩充了数据的 “覆盖范围”（让模型看到 “猫和狗之间的过渡状态”），相当于用少量数据造出了更         多 “虚拟样本”。
        痛点 2：模型容易 “死记硬背”（过拟合）如果只给模型看 “纯猫”“纯狗”，它可能会记住一些无关细节（比如某张猫图的背景是草地），而不是 “猫的本质特征”。Mixup 强制模型学习样本间的 “线性关系”—— 比如 “猫的特征         越多，标签越接近猫”，这会迫使模型去抓更本质、更通用的规律，而不是死记硬背特定样本。
      3. 最终效果：让模型更 “抗打”
        用 Mixup 训练后，模型在没见过的新数据上表现会更好（泛化能力更强），不容易因为数据小变化就 “翻车”。
        再举个生活化的类比：学认水果时，如果只给你看 “完整的苹果” 和 “完整的橘子”，你可能只记住 “苹果是圆的、橘子是橙的”；但如果给你看 “60% 苹果 + 40% 橘子” 的混合图，你就得去学 “形状圆润、果肉质感” 这种更         本质的特征 —— 下次遇到有点像苹果又有点像橘子的，你也能大概认出来，这就是 Mixup 的作用
        
   （3）学习率步长衰减：每 20 轮学习率减半，前期快速探索参数空间，后期精细调参，提升收敛稳定性。
        
   （4）早停策略：监控验证集准确率，连续 10 轮无提升则终止训练，保存泛化能力最强的模型，避免无效训练。
        
   （5）进阶数据增强：在任务三的随机裁剪、水平翻转基础上，新增随机旋转（±15°）和颜色抖动（亮度 / 对比度 / 饱和度），提升模型对角度、光照变化的鲁棒性。
        
  2. 结构优化
   加深卷积层：从任务三的 3 层卷积扩展为 4 层卷积，提升模型对细粒度特征的提取能力。
        
   批量归一化（BN）：每一层卷积后加入 BN 层，解决深层网络的 “内部协变量偏移” 问题，加速收敛，稳定训练过程。
   
   正则化强化：将 Dropout 率从 0.5 提高到 0.6，进一步缓解过拟合，缩小训练 / 验证集准确率差距。
  3. 工程规范
   固定随机种子：设置 seed=42，保证实验结果可复现，便于对比优化前后效果。
   
   自动日志记录：训练过程自动保存 .log 文件，完整记录每轮 Loss、准确率和学习率变化。
        
   参数量与 FLOPs 计算：使用 thop 库自动计算模型参数量和计算量，平衡高性能与轻量化。
