task2 学习率分析 当学习率调得非常大（例如 1.0）或非常小时（例如 0.00001）时，Loss 曲线会发生以下变化：

1.学习率非常大（例如 1.0） ： Loss 曲线变化 ：Loss 曲线会出现剧烈震荡，甚至可能发散（Loss 值持续增大）。 原因 ：学习率过大时，模型参数的更新步长过大，可能会跳过损失函数的最优解。每次参数更新都会在最优解附近大幅度摆动，导致模型无法稳定收敛。

2.学习率非常小（例如 0.00001） ： Loss 曲线变化 ：Loss 曲线下降非常缓慢，需要更多的迭代次数才能接近最优解。 原因 ：学习率过小时，模型参数的更新步长过小，每次迭代对损失函数的改进非常有限。虽然最终可能会收敛到最优解附近，但训练效率极低，需要大量的计算资源和时间。 过拟合判定 在训练过程中，模型是否出现过拟合现象，可以通过以下指标或图形来判断： 1.训练集 vs 测试集损失对比 ： 判断方法 ：将数据集分为训练集（代码中为 80%）和测试集（代码中为 20%）。在训练过程中，同时监控训练集和测试集的损失值。 过拟合现象 ：当训练集损失持续下降，而测试集损失在达到一定程度后开始上升，或两者的差距逐渐增大时，说明模型出现了过拟合。 代码实现 ：代码最后会计算并打印训练集和测试集的损失值，通过比较两者的差异来判断是否过拟合。 2.拟合曲线与真实数据对比 ： 判断方法 ：观察训练不同 epoch 时的拟合曲线与真实数据的关系。 过拟合现象 ：如果模型在训练数据上拟合得过于紧密（例如，对训练数据中的噪声也进行了拟合），而在测试数据上表现较差，说明出现了过拟合。 代码实现 ：代码会绘制训练 10、100、1000 个 epoch 时的拟合曲线与真实数据的对比图，通过观察曲线的平滑程度和对整体趋势的捕捉能力来判断是否过拟合。 总结 学习率 是神经网络训练中的关键超参数，需要选择合适的值以确保模型能够高效收敛到最优解。 过拟合 是模型训练中的常见问题，需要通过监控训练集和测试集的性能差异来及时发现并采取措施（如正则化、早停等）来缓解。

1-6 导入依赖库 把代码要用到的 “工具包” 都拿过来，比如读数据、画图、搭神经网络的工具

7-12 数据加载函数 专门读task2.csv文件，把 x、y 列的数据整理成模型能认的格式，返回 x 和 y

13-28 MLP 模型类 造一个 “智能猜数器”：3 层隐藏层（每层 128 个计算单元），能学 x 和 y 的非线性关系

29-45 模型训练函数 教猜数器学习：算误差→调参数→记误差，学指定轮数，最后返回每轮的误差值

46-60 可视化对比函数 画图：把真实 x-y 的点和模型猜的曲线画在一起，直观看猜得准不准

61-118 主函数（核心逻辑）代码的 “总指挥”：

读数据→拆训练 / 测试集
造模型→训 1000 轮→画误差曲线
对比 10/100/1000 轮的拟合效果
试 3 种学习率→画各自的误差曲线
算训练 / 测试误差→判断是否过拟合 119-120 运行入口 运行脚本时，自动启动主函数，让所有逻辑跑起来
